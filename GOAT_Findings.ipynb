{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9XnD3EotX67fmlfzD/Zgx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arun8nov/GOAT-Findings/blob/main/GOAT_Findings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvt6YjYkUtby",
        "outputId": "7ebfae53-5b0e-4bce-ef44-216788030cbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 39.4/112.6 GB disk)\n"
          ]
        }
      ],
      "source": [
        "# YOLO 11 segmentation\n",
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/v2.zip'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5cPabAYVmxR",
        "outputId": "a953e922-83de-4c7b-c3fe-4b15b227ed4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/v2.zip\n",
            "   creating: GOAT/\n",
            "  inflating: GOAT/data.yaml          \n",
            "  inflating: GOAT/README.dataset.txt  \n",
            "  inflating: GOAT/README.roboflow.txt  \n",
            "   creating: GOAT/test/\n",
            "   creating: GOAT/test/images/\n",
            "  inflating: GOAT/test/images/goat1_mp4-0004_jpg.rf.1fc40d5bde412adc6a025ac19f408fa2.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0010_jpg.rf.bc4f30f93b901c79c9f67cd3f47ff592.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0018_jpg.rf.b06e87c5019d4150d56d9fa5430f0e33.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0022_jpg.rf.eb03de9a89c3161ea2172b9966568e05.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0027_jpg.rf.b10c1c9490ad3571cc7fc5b50a9076df.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0038_jpg.rf.cad91c3a83acf2a4e49ed51a723cc324.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0046_jpg.rf.3a047702b600f1832babbc1effb0b07e.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0048_jpg.rf.2f3755d8bf980993e37584a951b40f38.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0049_jpg.rf.058d6809c3331a03240ce206aad53a59.jpg  \n",
            "  inflating: GOAT/test/images/goat1_mp4-0052_jpg.rf.450eb3db1b9a814873bd8d86fced7dcf.jpg  \n",
            "  inflating: GOAT/test/images/goat2_mp4-0002_jpg.rf.b60b1d8cfe4664df0db94793c86b16c8.jpg  \n",
            "  inflating: GOAT/test/images/goat2_mp4-0009_jpg.rf.88cff771d02c87d670796d89f82a41e0.jpg  \n",
            "  inflating: GOAT/test/images/goat2_mp4-0012_jpg.rf.94ea7bee4cbf534f0da5d1b2ee892171.jpg  \n",
            "  inflating: GOAT/test/images/goat2_mp4-0013_jpg.rf.2f94e58fbcd2216b09abe314f93bf3b9.jpg  \n",
            "  inflating: GOAT/test/images/goat2_mp4-0019_jpg.rf.2da654ebc882373e27c52ce78f73aa0d.jpg  \n",
            "  inflating: GOAT/test/images/goat2_mp4-0022_jpg.rf.b37fdc71f65ef043b5bd3bb76d140d3f.jpg  \n",
            "  inflating: GOAT/test/images/goat2_mp4-0024_jpg.rf.bddea4ed093eb42107431f4983b5af25.jpg  \n",
            "  inflating: GOAT/test/images/goat5_mp4-0216_jpg.rf.10a4f74cad5690b3d96847db831e6799.jpg  \n",
            "  inflating: GOAT/test/images/goat_mp4-0004_jpg.rf.c6c056ac1d72dc18410e5dd00b40c0da.jpg  \n",
            "  inflating: GOAT/test/images/goat_mp4-0028_jpg.rf.6965ec61416c0cd4e068f1ae96ca8bc4.jpg  \n",
            "   creating: GOAT/test/labels/\n",
            "  inflating: GOAT/test/labels/goat1_mp4-0004_jpg.rf.1fc40d5bde412adc6a025ac19f408fa2.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0010_jpg.rf.bc4f30f93b901c79c9f67cd3f47ff592.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0018_jpg.rf.b06e87c5019d4150d56d9fa5430f0e33.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0022_jpg.rf.eb03de9a89c3161ea2172b9966568e05.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0027_jpg.rf.b10c1c9490ad3571cc7fc5b50a9076df.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0038_jpg.rf.cad91c3a83acf2a4e49ed51a723cc324.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0046_jpg.rf.3a047702b600f1832babbc1effb0b07e.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0048_jpg.rf.2f3755d8bf980993e37584a951b40f38.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0049_jpg.rf.058d6809c3331a03240ce206aad53a59.txt  \n",
            "  inflating: GOAT/test/labels/goat1_mp4-0052_jpg.rf.450eb3db1b9a814873bd8d86fced7dcf.txt  \n",
            "  inflating: GOAT/test/labels/goat2_mp4-0002_jpg.rf.b60b1d8cfe4664df0db94793c86b16c8.txt  \n",
            "  inflating: GOAT/test/labels/goat2_mp4-0009_jpg.rf.88cff771d02c87d670796d89f82a41e0.txt  \n",
            "  inflating: GOAT/test/labels/goat2_mp4-0012_jpg.rf.94ea7bee4cbf534f0da5d1b2ee892171.txt  \n",
            "  inflating: GOAT/test/labels/goat2_mp4-0013_jpg.rf.2f94e58fbcd2216b09abe314f93bf3b9.txt  \n",
            "  inflating: GOAT/test/labels/goat2_mp4-0019_jpg.rf.2da654ebc882373e27c52ce78f73aa0d.txt  \n",
            "  inflating: GOAT/test/labels/goat2_mp4-0022_jpg.rf.b37fdc71f65ef043b5bd3bb76d140d3f.txt  \n",
            "  inflating: GOAT/test/labels/goat2_mp4-0024_jpg.rf.bddea4ed093eb42107431f4983b5af25.txt  \n",
            "  inflating: GOAT/test/labels/goat5_mp4-0216_jpg.rf.10a4f74cad5690b3d96847db831e6799.txt  \n",
            "  inflating: GOAT/test/labels/goat_mp4-0004_jpg.rf.c6c056ac1d72dc18410e5dd00b40c0da.txt  \n",
            "  inflating: GOAT/test/labels/goat_mp4-0028_jpg.rf.6965ec61416c0cd4e068f1ae96ca8bc4.txt  \n",
            "   creating: GOAT/train/\n",
            "   creating: GOAT/train/images/\n",
            "  inflating: GOAT/train/images/goat1_mp4-0000_jpg.rf.3019a2a89a44f6476e47e82534085680.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0000_jpg.rf.443a926a7cad64cd5672ec9aadf08b25.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0000_jpg.rf.f1ff3e20a473b574bc66897eaa128a6f.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0001_jpg.rf.66191ff2b25e241ffacfea3b9388a4bd.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0001_jpg.rf.c411d220b6f035df93878461aaa21d61.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0001_jpg.rf.df1b5f740c48a2b897a393f20fd4c648.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0002_jpg.rf.26eab1248fa636eabd467bbafcc75331.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0002_jpg.rf.83c3d8d617292f90057e28f1e806ba74.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0002_jpg.rf.ff02de5a8889126d15760edf14ba006c.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0003_jpg.rf.7ba40299af934f764b8dd13a4c462ee4.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0003_jpg.rf.a599edfdaab9c4510069627d75f83aae.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0003_jpg.rf.e3b7560285b94966a2c3304d1e6dd612.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0005_jpg.rf.57b1069ea2704aa3dff0325f8c4dba7f.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0005_jpg.rf.6f0998493bcf81ca88de7fb7442feef1.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0005_jpg.rf.d6710628d0d9c02f6c366a88d5a3e299.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0011_jpg.rf.3ba1089f0251d93d02157f2c79bee85b.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0011_jpg.rf.6bc3e57b4cf7ae6211b993294980e4d5.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0011_jpg.rf.fa20be5903cc38ef972262da1a407fbb.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0012_jpg.rf.0b2b4ddf7fdca423b14e06b805326d16.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0012_jpg.rf.16b53d8ebdddc8ec6b49ce4e9c56b6f9.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0012_jpg.rf.8b99703dc835d05531dfb34849151b85.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0013_jpg.rf.04641943363cbddcede99c9c86fae8c4.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0013_jpg.rf.0732f114ed9ae0ba6f41ef1de875e2c1.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0013_jpg.rf.641d945549538747c25a5de520d94d3d.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0014_jpg.rf.647d858adc60aa8e6585b4e8077cd0f0.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0014_jpg.rf.8d797f1ea4feec5762d29d918defc71f.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0014_jpg.rf.ffc60c22e44425510092b1eb0435fcf9.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0015_jpg.rf.10a9a574f228986f6c1ec009d1b2cb52.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0015_jpg.rf.365d25564172bc300ddfe4fc0ee547f2.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0015_jpg.rf.a4651b145b4d542902c0cb1bba31e05d.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0016_jpg.rf.2051575d6901ad6e0bd4b8121b34e6b9.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0016_jpg.rf.be11fc393e255cbc3436952751810c8a.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0016_jpg.rf.d729948914d7cff0dd879d422a208cc5.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0017_jpg.rf.284e3decd96253399d2c7a55aa7b17d1.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0017_jpg.rf.46bb049f01c702d41e22b17ac6101004.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0017_jpg.rf.ac204ae9a59d4127e6f3cb9e44f89491.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0019_jpg.rf.453c27deb0cfeaa36036732a82f1b1d8.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0019_jpg.rf.49d87b8d63c7996b8dd031b84a7a556e.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0019_jpg.rf.9052e8c650d0221d4a5aa3063e2effe6.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0020_jpg.rf.3a38fb0862b4ee8e346aca68054e199b.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0020_jpg.rf.3d62b1b2b1015c3864d00821d1aff23e.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0020_jpg.rf.d62282bfd29ce0455fadb74cc58004b9.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0021_jpg.rf.9f507d5bd823380a0dedb9602baa5ada.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0021_jpg.rf.ab3fccae437b5519bd3de7c152534389.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0021_jpg.rf.ffab4336e772834fd83e0cfa82014cf5.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0023_jpg.rf.30c91de0122d812a80a3206924d12bb7.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0023_jpg.rf.560197d5f2a22a4aaa9d66a61b67dec8.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0023_jpg.rf.ffaa9c4c6e9bc3423028c93200bcb003.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0025_jpg.rf.0b3ca61e5014e5c6acc3da5cee254988.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0025_jpg.rf.883ac126a1e6e64934d9877ecd93ce2a.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0025_jpg.rf.d99d5f9a7aa05a0cdf4463f61dd5b43e.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0026_jpg.rf.1d920665e0f3387d04f723407c835981.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0026_jpg.rf.626f6fa7c3b86fb38b9dbb5249e65548.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0026_jpg.rf.8f7cd9d8bed311ea2aee11c0b8be9d2e.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0028_jpg.rf.441a65b763c27fb3764a592f7a1d0040.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0028_jpg.rf.ecc6613a8675c325658ab3a9b92d721d.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0028_jpg.rf.f382351d72d0867ae626dfcd19197049.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0029_jpg.rf.6b4cbe7918ea2a998d9669059b30fe81.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0029_jpg.rf.bbdd7d35a1db9ee3c1a26fb3294c275e.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0029_jpg.rf.c7748546daeecf1e7f9e3acfa9c86bd4.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0030_jpg.rf.5186bf3773136a402e63353191aba425.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0030_jpg.rf.6be893b21b559fb869dfdd9af1348d09.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0030_jpg.rf.6f29c902be9020b34fd02a28f348c37a.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0031_jpg.rf.880ff525ffcef41e9925f7662f9cfbff.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0031_jpg.rf.952394b09755c0e0c2fb3d708772ed8a.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0031_jpg.rf.d5f40ffa7827ccdcebda80b8f5cf47f5.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0032_jpg.rf.19e26436a5048c089722e249292a209c.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0032_jpg.rf.6374ca76dfd848dfecdbab8a31847242.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0032_jpg.rf.67e44f20567e054414642f68084c7e4e.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0034_jpg.rf.03ea5a376a5ff36acc40ced8ae9cbe16.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0034_jpg.rf.2cf2b6d84e55e6aaa1f7bdd355a19fb3.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0034_jpg.rf.83ec24301fb38500cff87d06d1068eff.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0036_jpg.rf.12ae1c8eeb81da59b0c9a5bec8f6b71c.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0036_jpg.rf.75bd726cff1761bacf3d9d7edf915d2f.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0036_jpg.rf.c0266306d7796dc480a72743cbc9d607.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0039_jpg.rf.01ec0ed07ddbe61051142381af37a625.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0039_jpg.rf.477b398834dc498bb8d7a1bc35a5b259.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0039_jpg.rf.8fc3e40d2fd61b32ce1a62f93e02938a.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0040_jpg.rf.36bf12ce9f224d1fbc014a6ef72ec472.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0040_jpg.rf.448dfadd04ffecce2e02abfa34621d95.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0040_jpg.rf.e0e0813c4d69bd8229bb78177eb29eb0.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0041_jpg.rf.55889bf9e89ccf661f4ca3f9b0a05dff.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0041_jpg.rf.c5e2ad08b13b5084240ba451d95a8686.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0041_jpg.rf.faa669b6970ddff4dc6af18fbc515b2d.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0042_jpg.rf.55502054fb7e0f83d7f6f21d403e75f1.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0042_jpg.rf.c681b6248b68429e3f63498b1cae1a65.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0042_jpg.rf.fbab57f7a4fb2811ca8dad3309995a4b.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0043_jpg.rf.0cbebacfa6fd369cd132decaa6f4a3a7.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0043_jpg.rf.d3623cad7ec1c1641acb3d94f7256d2c.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0043_jpg.rf.dff268ed129a57f5780ee7bb827f3f3d.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0044_jpg.rf.094db36c6ca30d458c66e9f84ea8b14a.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0044_jpg.rf.3ec74f74b6df36a9c91f357c6f710be6.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0044_jpg.rf.e2a3fdbd7fa05c121324c9ae7c3c1b0f.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0045_jpg.rf.15325942010ced1d77ca738c1d709ed5.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0045_jpg.rf.9ea14ef28cf44a6b630bf2e9a1d1309b.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0045_jpg.rf.b07c994f4af1ba789915cf943b8d2aac.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0047_jpg.rf.328427c12276856a74f31f31401176c7.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0047_jpg.rf.91ec314965165315168eb589b2ff4c31.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0047_jpg.rf.e201c8996a9cabe2094472731a62951e.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0050_jpg.rf.38019abb882de94e712738b2d00dff12.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0050_jpg.rf.9f40863ce54d45a97abf1684386913df.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0050_jpg.rf.fbecd0b5d7b6be4f8ffb18b1fab18e0b.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0053_jpg.rf.0d025bdd8384ce6bd75523e16e623ce9.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0053_jpg.rf.6b0d8849144af47b28c84842a31ff4f4.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0053_jpg.rf.a39f1cdb3a92bc17403016505c0a5aa7.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0055_jpg.rf.02ec0a40127b8f5811a9addfff056c31.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0055_jpg.rf.19f6f649ba49bd8cc946c23c27d6b89c.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0055_jpg.rf.bc7c369a962c30aa9c8b5248c350392f.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0056_jpg.rf.82189dbe9e111233a08383bbda7eb933.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0056_jpg.rf.8821c9b948a4c0f7aefe83bcf26b4862.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0056_jpg.rf.8a7d098de30a48cd9e192d4bba21ef22.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0057_jpg.rf.02a04e13fded3f90e68898489386b1c1.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0057_jpg.rf.3f028f81428c2d24c58a287bbd986faa.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0057_jpg.rf.d12350f2d73f17bbfc7eba679a1e639e.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0058_jpg.rf.1b2dd977ec489e918638e959d53bbd51.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0058_jpg.rf.29c617c7bc0ba6826e2d4201f00a5584.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0058_jpg.rf.4460de0b9af6531e7a4a5957255cb3c4.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0059_jpg.rf.64b051e243d2051e69c032daa45ae7b1.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0059_jpg.rf.6b28386b2cd8e7493727af862bda76ce.jpg  \n",
            "  inflating: GOAT/train/images/goat1_mp4-0059_jpg.rf.7576c98b4781dbe9c729daedfb26e7dc.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0000_jpg.rf.087ce48b06bce06ad1408de60f271b65.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0000_jpg.rf.7ffd5b43b0976ebd0ce6ec382549db52.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0000_jpg.rf.960f5ae05814943fc7e800fa4b324c55.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0001_jpg.rf.11acab64c26bf472573d39b48b2beea9.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0001_jpg.rf.b10b49a281891914cb545d8939686ecc.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0001_jpg.rf.e81f535eba49cf132cfd03d57ba72222.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0003_jpg.rf.27045c183ffd9fbcf0a35e53dbdb44cc.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0003_jpg.rf.36aa7af0d0b4990a82fcf18563950fb0.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0003_jpg.rf.6e536e1663a7492fe59074eadd42e87c.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0004_jpg.rf.57aa2bc2e67bd58f24fb94ba6f4ffd2d.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0004_jpg.rf.5f780097b22a6c515b4d5e9c769dac36.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0004_jpg.rf.7f1b6704cd11ec4165fcbeb9234da5fa.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0005_jpg.rf.18c0048ba55b3ba740ec30b696bb1804.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0005_jpg.rf.31f3f95c4666a797031c64aaad8d880f.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0005_jpg.rf.eaee49df9d0bd69fe9e47f35066ff8e7.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0006_jpg.rf.1ff2998f4d0d66d67a66e95ee2128089.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0006_jpg.rf.661db810f6fa2cb4eb29db6fd1fe7a5b.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0006_jpg.rf.9912052aecdae9593618401254ded178.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0007_jpg.rf.0a727de75762ce8ef8d160babc4c636d.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0007_jpg.rf.4d85e98dfd4bf2a996d7916110c4f138.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0007_jpg.rf.e2a09dd855278011b5513301ff2241a5.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0008_jpg.rf.36bdf4473373ce1b5206231b03150fb8.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0008_jpg.rf.5f02cd5c1cb901dd436666d63e29369b.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0008_jpg.rf.64348ef94ee4897dec3f585f16c2fdb2.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0011_jpg.rf.7e45bfad6be92623e733c6f10a8963f7.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0011_jpg.rf.e1213465a07611a482c90a686b11da21.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0011_jpg.rf.e1deed66d5c552ec08d8b6c6fd282bb3.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0015_jpg.rf.f5a389fd73ffea583bf2d7d5f97763b9.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0015_jpg.rf.fc5c4507ac23fb56335aa13a601f5990.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0016_jpg.rf.4ca93c35b3fc8dfef89313ae54f0e3f0.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0016_jpg.rf.7ca4f6afeff03c852d349b987b3dd796.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0016_jpg.rf.86d1cef6610a251dc5205ef27b6a6fcf.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0017_jpg.rf.6c520bea781c350118700524842be73d.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0017_jpg.rf.71c23e59f829ebbb69434f6af1275a0c.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0017_jpg.rf.d60a7ad7b1d3f33c82ac67b6077b199e.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0021_jpg.rf.238437d776ef2d16b16ac5128697feb7.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0021_jpg.rf.8cdc94075c1fd52f2a6215d2466bf33a.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0021_jpg.rf.b1ca076f56be3aee44ed164d15a995bc.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0023_jpg.rf.1ae2bad6ec4879a6e32c1fb2a309c054.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0023_jpg.rf.57ccacb4068c78a2a8c923b98856267c.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0023_jpg.rf.737976fade76aa3073d68d953e83c228.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0025_jpg.rf.630f3e08775b0611dd82f668830d49ff.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0025_jpg.rf.850d3cf6613c2fe4518530cccf8bea4f.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0025_jpg.rf.d6c17ef9d9a6f5287a8379ea184f94ce.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0026_jpg.rf.8939dd2c90d18da22004c6f92653718a.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0026_jpg.rf.a9f272a915c540ad6eb5917078b30aef.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0026_jpg.rf.d468e18926e1b7dbf091d6deb9e155fd.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0028_jpg.rf.14f232c280123496d340c08e332ad63e.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0028_jpg.rf.4e1d04ddcaea9ec450228b8465d44400.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0028_jpg.rf.d3ec0d7396dffa54748e2d47d6c423b9.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0030_jpg.rf.0f121277e1a19a74df60607d8f101643.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0030_jpg.rf.be39b792d08a63b88c5c7087721ab354.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0030_jpg.rf.ffe78078705bb4448847ef07c0ca8bfd.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0031_jpg.rf.80e21c4bb629f74ed826af5462d36e2a.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0031_jpg.rf.9ea2ba2818acf717729878007a5ae1fb.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0031_jpg.rf.abe1eb37b64d7f6cf9097df706306341.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0033_jpg.rf.1273ded05aba83bb02422a775e8f8a4e.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0033_jpg.rf.18bf6e4177168be361bf8a67cb321abe.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0033_jpg.rf.fed942598ebf4739e6ca479a0795b13c.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0036_jpg.rf.3917915ef83872c99519299442cf5c47.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0036_jpg.rf.d41e7ea79b024cafedd911ca3e1228bf.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0036_jpg.rf.f7ee9af38040f1a594ff4120be1aa787.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0037_jpg.rf.043c52d1c7665d2982233681b4639b39.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0037_jpg.rf.06e9c0404778183e13484e1bddf1ab30.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0037_jpg.rf.e3b5cd9d7f46a589388481897d8d0a44.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0038_jpg.rf.4e21d45a4880703d7b0626bbfa6c74d3.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0038_jpg.rf.72a75958a13d7035a85b0603abdebf8d.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0038_jpg.rf.f663e180fee908b12763ce5ab054572b.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0041_jpg.rf.ce3a2ff5d556b891f02fed187c855326.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0041_jpg.rf.d47dff79ac84eaa445b65e4466bb8d32.jpg  \n",
            "  inflating: GOAT/train/images/goat2_mp4-0041_jpg.rf.e5a3b37622ce4999c8ef6e375d527006.jpg  \n",
            "  inflating: GOAT/train/images/goat5_mp4-0213_jpg.rf.e4a81039a5a5bbf182fb6043c00aae47.jpg  \n",
            "  inflating: GOAT/train/images/goat5_mp4-0213_jpg.rf.eda97901e39cacf512be9f563ca8f1e4.jpg  \n",
            "  inflating: GOAT/train/images/goat5_mp4-0213_jpg.rf.ffcbe16024e00d55f31c33b30ed82a43.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0003_jpg.rf.6cd8c9c25abf2b8793748dcfc97bf54a.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0003_jpg.rf.afff54e18304fd3f53e5d2b1e752cde8.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0003_jpg.rf.dd9b78a2485e73bed37d3bc632339a35.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0008_jpg.rf.17bf6219bb25852d3573c6b7ffd9630e.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0008_jpg.rf.5a7431641178c4b30d3c933d0ef4500b.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0008_jpg.rf.ee9d7e8851aecf19e67b88a2a9c3d9f8.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0010_jpg.rf.5d9df78e95812a9a4d3a596c30a8d94a.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0010_jpg.rf.7a44315afc709920868f37b4cc48e882.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0010_jpg.rf.8bbe2270fbb2d7826ce704468349bd85.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0014_jpg.rf.3a38704c2cb60562b05062c1e4e98854.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0014_jpg.rf.8ce70799ca22b57c8fc53149e7492e49.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0014_jpg.rf.a9bcbd79c95030a0005397a63bdc718e.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0017_jpg.rf.1641008688df6ad2d347580a0c69bd5f.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0017_jpg.rf.4651728b12fe85df46d0931c6be99493.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0017_jpg.rf.6d90effb25e5018a3b4f6cf3e92af8ad.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0019_jpg.rf.4872f3f35293adf3e73cfa599aea129c.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0019_jpg.rf.65fbf0b7c37de82a0d2bd2c388024d60.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0019_jpg.rf.7310047b6e9ec9902655b24a5cfbc6b4.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0020_jpg.rf.6baa19a8d98a68d64d5dba79b915744e.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0020_jpg.rf.c5616e67b35774e3a2c7031cc09f328a.jpg  \n",
            "  inflating: GOAT/train/images/goat_mp4-0020_jpg.rf.feaa7c0a0da099a7b848e638c8f83015.jpg  \n",
            "   creating: GOAT/train/labels/\n",
            "  inflating: GOAT/train/labels/goat1_mp4-0000_jpg.rf.3019a2a89a44f6476e47e82534085680.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0000_jpg.rf.443a926a7cad64cd5672ec9aadf08b25.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0000_jpg.rf.f1ff3e20a473b574bc66897eaa128a6f.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0001_jpg.rf.66191ff2b25e241ffacfea3b9388a4bd.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0001_jpg.rf.c411d220b6f035df93878461aaa21d61.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0001_jpg.rf.df1b5f740c48a2b897a393f20fd4c648.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0002_jpg.rf.26eab1248fa636eabd467bbafcc75331.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0002_jpg.rf.83c3d8d617292f90057e28f1e806ba74.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0002_jpg.rf.ff02de5a8889126d15760edf14ba006c.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0003_jpg.rf.7ba40299af934f764b8dd13a4c462ee4.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0003_jpg.rf.a599edfdaab9c4510069627d75f83aae.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0003_jpg.rf.e3b7560285b94966a2c3304d1e6dd612.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0005_jpg.rf.57b1069ea2704aa3dff0325f8c4dba7f.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0005_jpg.rf.6f0998493bcf81ca88de7fb7442feef1.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0005_jpg.rf.d6710628d0d9c02f6c366a88d5a3e299.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0011_jpg.rf.3ba1089f0251d93d02157f2c79bee85b.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0011_jpg.rf.6bc3e57b4cf7ae6211b993294980e4d5.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0011_jpg.rf.fa20be5903cc38ef972262da1a407fbb.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0012_jpg.rf.0b2b4ddf7fdca423b14e06b805326d16.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0012_jpg.rf.16b53d8ebdddc8ec6b49ce4e9c56b6f9.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0012_jpg.rf.8b99703dc835d05531dfb34849151b85.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0013_jpg.rf.04641943363cbddcede99c9c86fae8c4.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0013_jpg.rf.0732f114ed9ae0ba6f41ef1de875e2c1.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0013_jpg.rf.641d945549538747c25a5de520d94d3d.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0014_jpg.rf.647d858adc60aa8e6585b4e8077cd0f0.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0014_jpg.rf.8d797f1ea4feec5762d29d918defc71f.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0014_jpg.rf.ffc60c22e44425510092b1eb0435fcf9.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0015_jpg.rf.10a9a574f228986f6c1ec009d1b2cb52.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0015_jpg.rf.365d25564172bc300ddfe4fc0ee547f2.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0015_jpg.rf.a4651b145b4d542902c0cb1bba31e05d.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0016_jpg.rf.2051575d6901ad6e0bd4b8121b34e6b9.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0016_jpg.rf.be11fc393e255cbc3436952751810c8a.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0016_jpg.rf.d729948914d7cff0dd879d422a208cc5.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0017_jpg.rf.284e3decd96253399d2c7a55aa7b17d1.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0017_jpg.rf.46bb049f01c702d41e22b17ac6101004.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0017_jpg.rf.ac204ae9a59d4127e6f3cb9e44f89491.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0019_jpg.rf.453c27deb0cfeaa36036732a82f1b1d8.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0019_jpg.rf.49d87b8d63c7996b8dd031b84a7a556e.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0019_jpg.rf.9052e8c650d0221d4a5aa3063e2effe6.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0020_jpg.rf.3a38fb0862b4ee8e346aca68054e199b.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0020_jpg.rf.3d62b1b2b1015c3864d00821d1aff23e.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0020_jpg.rf.d62282bfd29ce0455fadb74cc58004b9.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0021_jpg.rf.9f507d5bd823380a0dedb9602baa5ada.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0021_jpg.rf.ab3fccae437b5519bd3de7c152534389.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0021_jpg.rf.ffab4336e772834fd83e0cfa82014cf5.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0023_jpg.rf.30c91de0122d812a80a3206924d12bb7.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0023_jpg.rf.560197d5f2a22a4aaa9d66a61b67dec8.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0023_jpg.rf.ffaa9c4c6e9bc3423028c93200bcb003.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0025_jpg.rf.0b3ca61e5014e5c6acc3da5cee254988.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0025_jpg.rf.883ac126a1e6e64934d9877ecd93ce2a.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0025_jpg.rf.d99d5f9a7aa05a0cdf4463f61dd5b43e.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0026_jpg.rf.1d920665e0f3387d04f723407c835981.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0026_jpg.rf.626f6fa7c3b86fb38b9dbb5249e65548.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0026_jpg.rf.8f7cd9d8bed311ea2aee11c0b8be9d2e.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0028_jpg.rf.441a65b763c27fb3764a592f7a1d0040.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0028_jpg.rf.ecc6613a8675c325658ab3a9b92d721d.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0028_jpg.rf.f382351d72d0867ae626dfcd19197049.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0029_jpg.rf.6b4cbe7918ea2a998d9669059b30fe81.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0029_jpg.rf.bbdd7d35a1db9ee3c1a26fb3294c275e.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0029_jpg.rf.c7748546daeecf1e7f9e3acfa9c86bd4.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0030_jpg.rf.5186bf3773136a402e63353191aba425.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0030_jpg.rf.6be893b21b559fb869dfdd9af1348d09.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0030_jpg.rf.6f29c902be9020b34fd02a28f348c37a.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0031_jpg.rf.880ff525ffcef41e9925f7662f9cfbff.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0031_jpg.rf.952394b09755c0e0c2fb3d708772ed8a.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0031_jpg.rf.d5f40ffa7827ccdcebda80b8f5cf47f5.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0032_jpg.rf.19e26436a5048c089722e249292a209c.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0032_jpg.rf.6374ca76dfd848dfecdbab8a31847242.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0032_jpg.rf.67e44f20567e054414642f68084c7e4e.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0034_jpg.rf.03ea5a376a5ff36acc40ced8ae9cbe16.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0034_jpg.rf.2cf2b6d84e55e6aaa1f7bdd355a19fb3.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0034_jpg.rf.83ec24301fb38500cff87d06d1068eff.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0036_jpg.rf.12ae1c8eeb81da59b0c9a5bec8f6b71c.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0036_jpg.rf.75bd726cff1761bacf3d9d7edf915d2f.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0036_jpg.rf.c0266306d7796dc480a72743cbc9d607.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0039_jpg.rf.01ec0ed07ddbe61051142381af37a625.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0039_jpg.rf.477b398834dc498bb8d7a1bc35a5b259.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0039_jpg.rf.8fc3e40d2fd61b32ce1a62f93e02938a.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0040_jpg.rf.36bf12ce9f224d1fbc014a6ef72ec472.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0040_jpg.rf.448dfadd04ffecce2e02abfa34621d95.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0040_jpg.rf.e0e0813c4d69bd8229bb78177eb29eb0.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0041_jpg.rf.55889bf9e89ccf661f4ca3f9b0a05dff.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0041_jpg.rf.c5e2ad08b13b5084240ba451d95a8686.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0041_jpg.rf.faa669b6970ddff4dc6af18fbc515b2d.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0042_jpg.rf.55502054fb7e0f83d7f6f21d403e75f1.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0042_jpg.rf.c681b6248b68429e3f63498b1cae1a65.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0042_jpg.rf.fbab57f7a4fb2811ca8dad3309995a4b.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0043_jpg.rf.0cbebacfa6fd369cd132decaa6f4a3a7.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0043_jpg.rf.d3623cad7ec1c1641acb3d94f7256d2c.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0043_jpg.rf.dff268ed129a57f5780ee7bb827f3f3d.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0044_jpg.rf.094db36c6ca30d458c66e9f84ea8b14a.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0044_jpg.rf.3ec74f74b6df36a9c91f357c6f710be6.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0044_jpg.rf.e2a3fdbd7fa05c121324c9ae7c3c1b0f.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0045_jpg.rf.15325942010ced1d77ca738c1d709ed5.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0045_jpg.rf.9ea14ef28cf44a6b630bf2e9a1d1309b.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0045_jpg.rf.b07c994f4af1ba789915cf943b8d2aac.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0047_jpg.rf.328427c12276856a74f31f31401176c7.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0047_jpg.rf.91ec314965165315168eb589b2ff4c31.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0047_jpg.rf.e201c8996a9cabe2094472731a62951e.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0050_jpg.rf.38019abb882de94e712738b2d00dff12.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0050_jpg.rf.9f40863ce54d45a97abf1684386913df.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0050_jpg.rf.fbecd0b5d7b6be4f8ffb18b1fab18e0b.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0053_jpg.rf.0d025bdd8384ce6bd75523e16e623ce9.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0053_jpg.rf.6b0d8849144af47b28c84842a31ff4f4.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0053_jpg.rf.a39f1cdb3a92bc17403016505c0a5aa7.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0055_jpg.rf.02ec0a40127b8f5811a9addfff056c31.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0055_jpg.rf.19f6f649ba49bd8cc946c23c27d6b89c.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0055_jpg.rf.bc7c369a962c30aa9c8b5248c350392f.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0056_jpg.rf.82189dbe9e111233a08383bbda7eb933.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0056_jpg.rf.8821c9b948a4c0f7aefe83bcf26b4862.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0056_jpg.rf.8a7d098de30a48cd9e192d4bba21ef22.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0057_jpg.rf.02a04e13fded3f90e68898489386b1c1.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0057_jpg.rf.3f028f81428c2d24c58a287bbd986faa.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0057_jpg.rf.d12350f2d73f17bbfc7eba679a1e639e.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0058_jpg.rf.1b2dd977ec489e918638e959d53bbd51.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0058_jpg.rf.29c617c7bc0ba6826e2d4201f00a5584.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0058_jpg.rf.4460de0b9af6531e7a4a5957255cb3c4.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0059_jpg.rf.64b051e243d2051e69c032daa45ae7b1.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0059_jpg.rf.6b28386b2cd8e7493727af862bda76ce.txt  \n",
            "  inflating: GOAT/train/labels/goat1_mp4-0059_jpg.rf.7576c98b4781dbe9c729daedfb26e7dc.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0000_jpg.rf.087ce48b06bce06ad1408de60f271b65.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0000_jpg.rf.7ffd5b43b0976ebd0ce6ec382549db52.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0000_jpg.rf.960f5ae05814943fc7e800fa4b324c55.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0001_jpg.rf.11acab64c26bf472573d39b48b2beea9.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0001_jpg.rf.b10b49a281891914cb545d8939686ecc.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0001_jpg.rf.e81f535eba49cf132cfd03d57ba72222.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0003_jpg.rf.27045c183ffd9fbcf0a35e53dbdb44cc.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0003_jpg.rf.36aa7af0d0b4990a82fcf18563950fb0.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0003_jpg.rf.6e536e1663a7492fe59074eadd42e87c.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0004_jpg.rf.57aa2bc2e67bd58f24fb94ba6f4ffd2d.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0004_jpg.rf.5f780097b22a6c515b4d5e9c769dac36.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0004_jpg.rf.7f1b6704cd11ec4165fcbeb9234da5fa.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0005_jpg.rf.18c0048ba55b3ba740ec30b696bb1804.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0005_jpg.rf.31f3f95c4666a797031c64aaad8d880f.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0005_jpg.rf.eaee49df9d0bd69fe9e47f35066ff8e7.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0006_jpg.rf.1ff2998f4d0d66d67a66e95ee2128089.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0006_jpg.rf.661db810f6fa2cb4eb29db6fd1fe7a5b.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0006_jpg.rf.9912052aecdae9593618401254ded178.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0007_jpg.rf.0a727de75762ce8ef8d160babc4c636d.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0007_jpg.rf.4d85e98dfd4bf2a996d7916110c4f138.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0007_jpg.rf.e2a09dd855278011b5513301ff2241a5.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0008_jpg.rf.36bdf4473373ce1b5206231b03150fb8.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0008_jpg.rf.5f02cd5c1cb901dd436666d63e29369b.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0008_jpg.rf.64348ef94ee4897dec3f585f16c2fdb2.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0011_jpg.rf.7e45bfad6be92623e733c6f10a8963f7.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0011_jpg.rf.e1213465a07611a482c90a686b11da21.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0011_jpg.rf.e1deed66d5c552ec08d8b6c6fd282bb3.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0015_jpg.rf.f5a389fd73ffea583bf2d7d5f97763b9.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0015_jpg.rf.fc5c4507ac23fb56335aa13a601f5990.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0016_jpg.rf.4ca93c35b3fc8dfef89313ae54f0e3f0.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0016_jpg.rf.7ca4f6afeff03c852d349b987b3dd796.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0016_jpg.rf.86d1cef6610a251dc5205ef27b6a6fcf.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0017_jpg.rf.6c520bea781c350118700524842be73d.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0017_jpg.rf.71c23e59f829ebbb69434f6af1275a0c.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0017_jpg.rf.d60a7ad7b1d3f33c82ac67b6077b199e.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0021_jpg.rf.238437d776ef2d16b16ac5128697feb7.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0021_jpg.rf.8cdc94075c1fd52f2a6215d2466bf33a.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0021_jpg.rf.b1ca076f56be3aee44ed164d15a995bc.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0023_jpg.rf.1ae2bad6ec4879a6e32c1fb2a309c054.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0023_jpg.rf.57ccacb4068c78a2a8c923b98856267c.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0023_jpg.rf.737976fade76aa3073d68d953e83c228.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0025_jpg.rf.630f3e08775b0611dd82f668830d49ff.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0025_jpg.rf.850d3cf6613c2fe4518530cccf8bea4f.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0025_jpg.rf.d6c17ef9d9a6f5287a8379ea184f94ce.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0026_jpg.rf.8939dd2c90d18da22004c6f92653718a.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0026_jpg.rf.a9f272a915c540ad6eb5917078b30aef.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0026_jpg.rf.d468e18926e1b7dbf091d6deb9e155fd.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0028_jpg.rf.14f232c280123496d340c08e332ad63e.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0028_jpg.rf.4e1d04ddcaea9ec450228b8465d44400.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0028_jpg.rf.d3ec0d7396dffa54748e2d47d6c423b9.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0030_jpg.rf.0f121277e1a19a74df60607d8f101643.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0030_jpg.rf.be39b792d08a63b88c5c7087721ab354.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0030_jpg.rf.ffe78078705bb4448847ef07c0ca8bfd.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0031_jpg.rf.80e21c4bb629f74ed826af5462d36e2a.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0031_jpg.rf.9ea2ba2818acf717729878007a5ae1fb.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0031_jpg.rf.abe1eb37b64d7f6cf9097df706306341.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0033_jpg.rf.1273ded05aba83bb02422a775e8f8a4e.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0033_jpg.rf.18bf6e4177168be361bf8a67cb321abe.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0033_jpg.rf.fed942598ebf4739e6ca479a0795b13c.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0036_jpg.rf.3917915ef83872c99519299442cf5c47.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0036_jpg.rf.d41e7ea79b024cafedd911ca3e1228bf.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0036_jpg.rf.f7ee9af38040f1a594ff4120be1aa787.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0037_jpg.rf.043c52d1c7665d2982233681b4639b39.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0037_jpg.rf.06e9c0404778183e13484e1bddf1ab30.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0037_jpg.rf.e3b5cd9d7f46a589388481897d8d0a44.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0038_jpg.rf.4e21d45a4880703d7b0626bbfa6c74d3.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0038_jpg.rf.72a75958a13d7035a85b0603abdebf8d.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0038_jpg.rf.f663e180fee908b12763ce5ab054572b.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0041_jpg.rf.ce3a2ff5d556b891f02fed187c855326.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0041_jpg.rf.d47dff79ac84eaa445b65e4466bb8d32.txt  \n",
            "  inflating: GOAT/train/labels/goat2_mp4-0041_jpg.rf.e5a3b37622ce4999c8ef6e375d527006.txt  \n",
            "  inflating: GOAT/train/labels/goat5_mp4-0213_jpg.rf.e4a81039a5a5bbf182fb6043c00aae47.txt  \n",
            "  inflating: GOAT/train/labels/goat5_mp4-0213_jpg.rf.eda97901e39cacf512be9f563ca8f1e4.txt  \n",
            "  inflating: GOAT/train/labels/goat5_mp4-0213_jpg.rf.ffcbe16024e00d55f31c33b30ed82a43.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0003_jpg.rf.6cd8c9c25abf2b8793748dcfc97bf54a.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0003_jpg.rf.afff54e18304fd3f53e5d2b1e752cde8.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0003_jpg.rf.dd9b78a2485e73bed37d3bc632339a35.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0008_jpg.rf.17bf6219bb25852d3573c6b7ffd9630e.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0008_jpg.rf.5a7431641178c4b30d3c933d0ef4500b.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0008_jpg.rf.ee9d7e8851aecf19e67b88a2a9c3d9f8.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0010_jpg.rf.5d9df78e95812a9a4d3a596c30a8d94a.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0010_jpg.rf.7a44315afc709920868f37b4cc48e882.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0010_jpg.rf.8bbe2270fbb2d7826ce704468349bd85.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0014_jpg.rf.3a38704c2cb60562b05062c1e4e98854.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0014_jpg.rf.8ce70799ca22b57c8fc53149e7492e49.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0014_jpg.rf.a9bcbd79c95030a0005397a63bdc718e.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0017_jpg.rf.1641008688df6ad2d347580a0c69bd5f.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0017_jpg.rf.4651728b12fe85df46d0931c6be99493.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0017_jpg.rf.6d90effb25e5018a3b4f6cf3e92af8ad.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0019_jpg.rf.4872f3f35293adf3e73cfa599aea129c.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0019_jpg.rf.65fbf0b7c37de82a0d2bd2c388024d60.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0019_jpg.rf.7310047b6e9ec9902655b24a5cfbc6b4.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0020_jpg.rf.6baa19a8d98a68d64d5dba79b915744e.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0020_jpg.rf.c5616e67b35774e3a2c7031cc09f328a.txt  \n",
            "  inflating: GOAT/train/labels/goat_mp4-0020_jpg.rf.feaa7c0a0da099a7b848e638c8f83015.txt  \n",
            "   creating: GOAT/valid/\n",
            "   creating: GOAT/valid/images/\n",
            "  inflating: GOAT/valid/images/goat1_mp4-0006_jpg.rf.282ea5b091cf27aee10215873662b497.jpg  \n",
            "  inflating: GOAT/valid/images/goat1_mp4-0008_jpg.rf.99d6c178902f3b96742e638645ed948d.jpg  \n",
            "  inflating: GOAT/valid/images/goat1_mp4-0009_jpg.rf.8772864f949c6ed78147054e3c19837d.jpg  \n",
            "  inflating: GOAT/valid/images/goat1_mp4-0024_jpg.rf.fc87c4a580624d657f501d41d6314a5a.jpg  \n",
            "  inflating: GOAT/valid/images/goat1_mp4-0033_jpg.rf.dd0f33a37d2c7bb1da5d0010cc3f5bdb.jpg  \n",
            "  inflating: GOAT/valid/images/goat1_mp4-0037_jpg.rf.d2dd9f4f87cb271b14202e045563f9cd.jpg  \n",
            "  inflating: GOAT/valid/images/goat1_mp4-0051_jpg.rf.88bc7dbb51742864fae3dbe68e275445.jpg  \n",
            "  inflating: GOAT/valid/images/goat1_mp4-0054_jpg.rf.c4338ab7c679e38910727c676ad5c66f.jpg  \n",
            "  inflating: GOAT/valid/images/goat1_mp4-0060_jpg.rf.9507be76823f2ee809e331a2afdeb323.jpg  \n",
            "  inflating: GOAT/valid/images/goat2_mp4-0010_jpg.rf.cda5f090e34a86023db05dfb164e11ee.jpg  \n",
            "  inflating: GOAT/valid/images/goat2_mp4-0014_jpg.rf.01bd339683bbc8eaf44162852b619cf1.jpg  \n",
            "  inflating: GOAT/valid/images/goat2_mp4-0018_jpg.rf.ea44681684b248ab6976a066b8dece8a.jpg  \n",
            "  inflating: GOAT/valid/images/goat2_mp4-0020_jpg.rf.0c897a1b765d0061d0aeb6d1662b57f9.jpg  \n",
            "  inflating: GOAT/valid/images/goat2_mp4-0027_jpg.rf.9a89ca2d33446237ec0d54016ab856d8.jpg  \n",
            "  inflating: GOAT/valid/images/goat2_mp4-0029_jpg.rf.55d7013774610d9df6f703e52b6653c7.jpg  \n",
            "  inflating: GOAT/valid/images/goat2_mp4-0034_jpg.rf.9a98acbf11838b6ac718245349905677.jpg  \n",
            "  inflating: GOAT/valid/images/goat_mp4-0009_jpg.rf.6decf59ba6af2ecfe01182c1c63cd604.jpg  \n",
            "  inflating: GOAT/valid/images/goat_mp4-0013_jpg.rf.7ce2802093717781e5c3e7b848910236.jpg  \n",
            "  inflating: GOAT/valid/images/goat_mp4-0015_jpg.rf.3c616e41bc310269fd197f8aba5ec10c.jpg  \n",
            "  inflating: GOAT/valid/images/goat_mp4-0016_jpg.rf.1c5f1c2669aa94a8aedd28c4ea67681d.jpg  \n",
            "  inflating: GOAT/valid/images/goat_mp4-0018_jpg.rf.9352db0e443bac44f960728396d1999d.jpg  \n",
            "   creating: GOAT/valid/labels/\n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0006_jpg.rf.282ea5b091cf27aee10215873662b497.txt  \n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0008_jpg.rf.99d6c178902f3b96742e638645ed948d.txt  \n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0009_jpg.rf.8772864f949c6ed78147054e3c19837d.txt  \n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0024_jpg.rf.fc87c4a580624d657f501d41d6314a5a.txt  \n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0033_jpg.rf.dd0f33a37d2c7bb1da5d0010cc3f5bdb.txt  \n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0037_jpg.rf.d2dd9f4f87cb271b14202e045563f9cd.txt  \n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0051_jpg.rf.88bc7dbb51742864fae3dbe68e275445.txt  \n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0054_jpg.rf.c4338ab7c679e38910727c676ad5c66f.txt  \n",
            "  inflating: GOAT/valid/labels/goat1_mp4-0060_jpg.rf.9507be76823f2ee809e331a2afdeb323.txt  \n",
            "  inflating: GOAT/valid/labels/goat2_mp4-0010_jpg.rf.cda5f090e34a86023db05dfb164e11ee.txt  \n",
            "  inflating: GOAT/valid/labels/goat2_mp4-0014_jpg.rf.01bd339683bbc8eaf44162852b619cf1.txt  \n",
            "  inflating: GOAT/valid/labels/goat2_mp4-0018_jpg.rf.ea44681684b248ab6976a066b8dece8a.txt  \n",
            "  inflating: GOAT/valid/labels/goat2_mp4-0020_jpg.rf.0c897a1b765d0061d0aeb6d1662b57f9.txt  \n",
            "  inflating: GOAT/valid/labels/goat2_mp4-0027_jpg.rf.9a89ca2d33446237ec0d54016ab856d8.txt  \n",
            "  inflating: GOAT/valid/labels/goat2_mp4-0029_jpg.rf.55d7013774610d9df6f703e52b6653c7.txt  \n",
            "  inflating: GOAT/valid/labels/goat2_mp4-0034_jpg.rf.9a98acbf11838b6ac718245349905677.txt  \n",
            "  inflating: GOAT/valid/labels/goat_mp4-0009_jpg.rf.6decf59ba6af2ecfe01182c1c63cd604.txt  \n",
            "  inflating: GOAT/valid/labels/goat_mp4-0013_jpg.rf.7ce2802093717781e5c3e7b848910236.txt  \n",
            "  inflating: GOAT/valid/labels/goat_mp4-0015_jpg.rf.3c616e41bc310269fd197f8aba5ec10c.txt  \n",
            "  inflating: GOAT/valid/labels/goat_mp4-0016_jpg.rf.1c5f1c2669aa94a8aedd28c4ea67681d.txt  \n",
            "  inflating: GOAT/valid/labels/goat_mp4-0018_jpg.rf.9352db0e443bac44f960728396d1999d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "Dxr_cx_YVPtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolo11x-seg.pt\")"
      ],
      "metadata": {
        "id": "GwBztNCyVhU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAkxO2C9IDfl",
        "outputId": "adfec4a9-61c1-4e5a-864c-b92d20f1c31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "YOLO(\n",
              "  (model): SegmentationModel(\n",
              "    (model): Sequential(\n",
              "      (0): Conv(\n",
              "        (conv): Conv2d(3, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv(\n",
              "        (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (2): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): Conv(\n",
              "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (4): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): Conv(\n",
              "        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (6): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): Conv(\n",
              "        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (8): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): SPPF(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "      )\n",
              "      (10): C2PSA(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): Sequential(\n",
              "          (0): PSABlock(\n",
              "            (attn): Attention(\n",
              "              (qkv): Conv(\n",
              "                (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "              (proj): Conv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "              (pe): Conv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "            )\n",
              "            (ffn): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): PSABlock(\n",
              "            (attn): Attention(\n",
              "              (qkv): Conv(\n",
              "                (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "              (proj): Conv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "              (pe): Conv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "            )\n",
              "            (ffn): Sequential(\n",
              "              (0): Conv(\n",
              "                (conv): Conv2d(384, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): Identity()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (12): Concat()\n",
              "      (13): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (15): Concat()\n",
              "      (16): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (17): Conv(\n",
              "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (18): Concat()\n",
              "      (19): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1152, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (20): Conv(\n",
              "        (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (21): Concat()\n",
              "      (22): C3k2(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (m): ModuleList(\n",
              "          (0-1): 2 x C3k(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "              (1): Bottleneck(\n",
              "                (cv1): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (23): Segment(\n",
              "        (cv2): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(384, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(768, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (cv3): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Conv2d(384, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
              "                (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Sequential(\n",
              "              (0): DWConv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (1): Conv(\n",
              "                (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Conv2d(384, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (dfl): DFL(\n",
              "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (proto): Proto(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (upsample): ConvTranspose2d(384, 384, kernel_size=(2, 2), stride=(2, 2))\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(384, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(384, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(768, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(\n",
        "    data = '/content/GOAT/data.yaml',\n",
        "    epochs=50,\n",
        "    imgsz=255,\n",
        "    batch = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOzFvpWwVji4",
        "outputId": "f6a3f2f5-908b-4f74-b3b9-9de8359a744e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.203 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/GOAT/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=255, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11x-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/segment/train6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
            "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
            "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
            "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
            "  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n",
            " 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n",
            " 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n",
            " 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n",
            " 23        [16, 19, 22]  1   8324342  ultralytics.nn.modules.head.Segment          [2, 32, 384, [384, 768, 768]] \n",
            "YOLO11x-seg summary: 379 layers, 62,052,566 parameters, 62,052,550 gradients, 297.0 GFLOPs\n",
            "\n",
            "Transferred 1071/1077 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "WARNING ⚠️ imgsz=[255] must be multiple of max stride 32, updating to [256]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1413.5±382.7 MB/s, size: 51.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/GOAT/train/labels.cache... 215 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 215/215 420.6Kit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 531.8±343.7 MB/s, size: 76.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/GOAT/valid/labels.cache... 21 images, 1 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 21/21 4.6Kit/s 0.0s\n",
            "Plotting labels to /content/runs/segment/train6/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 176 weight(decay=0.0), 187 weight(decay=0.0005), 186 bias(decay=0.0)\n",
            "Image sizes 256 train, 256 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/segment/train6\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      6.04G      1.578      3.191      3.082      1.463        193        256: 100% ━━━━━━━━━━━━ 7/7 0.4it/s 17.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.5it/s 2.2s\n",
            "                   all         21        115      0.343      0.304      0.289       0.17      0.357      0.294      0.284      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      6.61G      1.316      2.558      1.632      1.258        202        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         21        115      0.168      0.304      0.155     0.0805       0.13      0.321     0.0974     0.0389\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      6.61G      1.231      2.241      1.264      1.199        155        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
            "                   all         21        115   0.000564     0.0246   0.000302   4.95e-05          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      6.95G      1.253      2.325      1.127      1.232        188        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.1it/s 0.2s\n",
            "                   all         21        115          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      7.49G      1.299      2.348      1.111      1.234        214        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.7it/s 0.2s\n",
            "                   all         21        115          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      6.71G      1.342      2.331      1.133      1.265        188        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.2it/s 0.2s\n",
            "                   all         21        115          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      6.85G      1.334      2.352      1.155      1.255        214        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 5.2it/s 0.2s\n",
            "                   all         21        115          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      7.56G      1.297       2.22      1.118      1.232        220        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         21        115          0          0          0          0          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50       6.9G      1.251      2.298       1.01      1.217        219        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         21        115    0.00334     0.0606     0.0019   0.000498    0.00379     0.0349    0.00157   0.000363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      7.24G      1.219      2.104     0.9409      1.198        203        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.2it/s 0.2s\n",
            "                   all         21        115   0.000957     0.0349   0.000499    0.00012   0.000479     0.0175   0.000245   3.59e-05\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      7.57G       1.22      2.118     0.9688      1.192        180        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         21        115     0.0495     0.0833     0.0162    0.00738      0.044     0.0741     0.0121    0.00596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      6.97G      1.219      2.197     0.9578      1.185        181        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.1it/s 0.2s\n",
            "                   all         21        115     0.0605      0.117     0.0171    0.00681     0.0592     0.0431    0.00651    0.00188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50       7.1G      1.279      2.186     0.9674      1.188        219        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         21        115     0.0801        0.2     0.0446     0.0164     0.0672      0.183     0.0394     0.0119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50       7.8G       1.26      2.091     0.9727       1.21        154        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         21        115      0.344      0.499      0.289      0.148      0.331      0.492      0.261      0.102\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      6.73G      1.224      2.048     0.9424       1.18        252        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.453      0.503      0.375      0.183      0.439       0.51      0.353      0.129\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      7.26G      1.203      2.082     0.9346      1.178        171        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.587       0.58      0.569      0.291      0.504      0.548      0.459      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      7.78G       1.17      1.967     0.9246       1.16        182        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.563      0.626      0.591      0.339      0.546      0.618      0.558      0.246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      6.97G      1.152      1.938       0.87      1.155        208        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.662       0.63      0.643      0.368      0.618      0.587       0.56       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50       7.1G      1.133      1.974     0.8549      1.175        180        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         21        115      0.559      0.648      0.639      0.361      0.561      0.619      0.604      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      7.59G      1.133       1.99     0.8933      1.157        229        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.669      0.582      0.641      0.398      0.669      0.582      0.631      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      6.93G      1.126      1.886     0.8613      1.137        236        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.629      0.647      0.625      0.381      0.582      0.622       0.56       0.25\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      7.06G      1.101      1.845     0.8124       1.12        190        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115       0.68      0.704      0.718      0.426      0.665      0.688      0.697      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      7.41G      1.098      1.826     0.8328      1.109        219        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         21        115      0.708      0.727      0.743      0.453      0.705      0.729       0.75      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      6.95G      1.069      1.811     0.8045      1.113        221        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
            "                   all         21        115      0.625      0.617      0.661      0.406      0.613      0.645      0.675      0.352\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      7.09G      1.045      1.772     0.7832       1.09        223        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         21        115      0.627      0.741      0.702      0.428      0.635       0.75      0.697      0.364\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      7.59G     0.9996      1.686     0.7392       1.09        190        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.8it/s 0.4s\n",
            "                   all         21        115      0.615      0.765      0.724      0.487      0.626      0.776      0.724      0.403\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      6.91G     0.9926      1.664     0.7594      1.056        250        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.775       0.66      0.728      0.492      0.785       0.67      0.748      0.368\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      7.24G     0.9499      1.584     0.7043      1.071        155        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         21        115       0.73      0.631      0.698      0.461       0.73      0.631      0.702      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      7.39G      0.995      1.635     0.7411      1.074        201        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.744      0.745      0.781      0.537      0.755      0.753      0.782      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      6.96G     0.9618       1.65     0.7344      1.065        197        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.786      0.783      0.819      0.573      0.779      0.775        0.8      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50       7.1G     0.9349      1.614     0.7098      1.057        171        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5it/s 0.3s\n",
            "                   all         21        115      0.763      0.729      0.816      0.578      0.763      0.729      0.812      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      7.59G     0.8696      1.476     0.6464      1.011        225        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         21        115      0.728      0.789      0.797      0.576       0.74      0.803      0.807      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      6.93G     0.9257      1.568     0.6784      1.034        214        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         21        115        0.8      0.805      0.801      0.579        0.8      0.805      0.801      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      7.26G     0.9144      1.498     0.6717       1.04        209        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         21        115      0.742      0.803      0.813      0.587      0.742      0.803      0.799      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      7.42G     0.8946      1.523     0.6369       1.02        179        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9it/s 0.3s\n",
            "                   all         21        115      0.811      0.801      0.822      0.586      0.811      0.801      0.814      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      6.99G     0.8585      1.476     0.6255      1.028        173        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         21        115       0.83      0.827       0.84      0.628       0.83      0.827       0.84      0.553\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      7.13G     0.8566      1.449     0.6262      1.007        167        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115       0.85      0.813      0.851       0.62       0.85      0.813      0.839      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      7.76G     0.8457      1.375      0.608     0.9991        169        256: 100% ━━━━━━━━━━━━ 7/7 1.5it/s 4.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         21        115      0.818      0.787       0.84      0.614      0.818      0.787      0.831      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      6.91G      0.789      1.375     0.5708     0.9816        170        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         21        115      0.864      0.783      0.839      0.613      0.864      0.783      0.835      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      7.24G     0.8134       1.37     0.5696     0.9884        213        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         21        115      0.795      0.838      0.849      0.628      0.805      0.847      0.849      0.537\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      7.57G     0.7821       1.34      0.638     0.9987         98        256: 100% ━━━━━━━━━━━━ 7/7 1.2it/s 5.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         21        115      0.843      0.797      0.849      0.653      0.842      0.799      0.849      0.566\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      6.95G     0.7594      1.321     0.5997      0.981        131        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.872      0.786      0.853       0.64      0.872      0.786      0.853      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      7.09G     0.7192      1.288     0.5459     0.9636        129        256: 100% ━━━━━━━━━━━━ 7/7 1.6it/s 4.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7it/s 0.3s\n",
            "                   all         21        115      0.862      0.794      0.845      0.634      0.862      0.794      0.851      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      7.76G     0.7101      1.237     0.5375     0.9657        122        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         21        115      0.835       0.81      0.844      0.626      0.835       0.81      0.844      0.542\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50       6.9G     0.6858      1.227     0.5391     0.9556        144        256: 100% ━━━━━━━━━━━━ 7/7 1.8it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6it/s 0.3s\n",
            "                   all         21        115      0.851      0.812      0.848       0.63      0.851      0.812      0.849      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      7.23G     0.6769      1.197     0.5121     0.9519        115        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.9it/s 0.3s\n",
            "                   all         21        115      0.882      0.776      0.846      0.637      0.882      0.776      0.851      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      7.76G     0.6686      1.245     0.4962      0.929        119        256: 100% ━━━━━━━━━━━━ 7/7 1.8it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.2s\n",
            "                   all         21        115      0.874       0.79      0.855       0.66      0.874       0.79      0.863      0.559\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      6.93G     0.6473      1.096     0.4747     0.9215        119        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.8it/s 0.3s\n",
            "                   all         21        115      0.881      0.784      0.856      0.667      0.881      0.784      0.861      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      7.07G     0.6554      1.112     0.4741     0.9289        106        256: 100% ━━━━━━━━━━━━ 7/7 1.8it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 4.0it/s 0.3s\n",
            "                   all         21        115      0.855       0.81      0.853      0.665      0.855       0.81      0.854      0.565\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      7.56G     0.6406      1.142     0.4866     0.9409        112        256: 100% ━━━━━━━━━━━━ 7/7 1.7it/s 4.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         21        115       0.86       0.81      0.848      0.662       0.86       0.81      0.845      0.564\n",
            "\n",
            "50 epochs completed in 0.162 hours.\n",
            "Optimizer stripped from /content/runs/segment/train6/weights/last.pt, 124.7MB\n",
            "Optimizer stripped from /content/runs/segment/train6/weights/best.pt, 124.7MB\n",
            "\n",
            "Validating /content/runs/segment/train6/weights/best.pt...\n",
            "Ultralytics 8.3.203 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11x-seg summary (fused): 203 layers, 62,004,438 parameters, 0 gradients, 295.9 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2it/s 0.3s\n",
            "                   all         21        115      0.882      0.784      0.856      0.667      0.882      0.784      0.861      0.563\n",
            "                  goat         13         54      0.875      0.815      0.841      0.689      0.875      0.815      0.852      0.567\n",
            "                 sheep         12         61      0.888      0.754       0.87      0.644      0.888      0.754       0.87      0.559\n",
            "Speed: 0.1ms preprocess, 8.6ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/segment/train6\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ultralytics.utils.metrics.SegmentMetrics object with attributes:\n",
              "\n",
              "ap_class_index: array([0, 1])\n",
              "box: ultralytics.utils.metrics.Metric object\n",
              "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x79b7b033b080>\n",
              "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)', 'Precision-Recall(M)', 'F1-Confidence(M)', 'Precision-Confidence(M)', 'Recall-Confidence(M)']\n",
              "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.002521,   0.0012605,           0],\n",
              "       [          1,           1,           1, ...,   0.0029041,    0.001452,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.13027,     0.13027,     0.19614, ...,           0,           0,           0],\n",
              "       [    0.13272,     0.13272,     0.17982, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.069959,    0.069959,     0.10943, ...,           1,           1,           1],\n",
              "       [   0.071341,    0.071341,    0.099299, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.94444,     0.94444,     0.94444, ...,           0,           0,           0],\n",
              "       [    0.95082,     0.95082,     0.95082, ...,           0,           0,           0]]), 'Confidence', 'Recall'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.002521,   0.0012605,           0],\n",
              "       [          1,           1,           1, ...,   0.0029041,    0.001452,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.13027,     0.13027,     0.19614, ...,           0,           0,           0],\n",
              "       [    0.13272,     0.13272,     0.17982, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.069959,    0.069959,     0.10943, ...,           1,           1,           1],\n",
              "       [   0.071341,    0.071341,    0.099299, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
              "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
              "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
              "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
              "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
              "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
              "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
              "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
              "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
              "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
              "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
              "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
              "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
              "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
              "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
              "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
              "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
              "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
              "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
              "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
              "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
              "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
              "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
              "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
              "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
              "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
              "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
              "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
              "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
              "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
              "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
              "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
              "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
              "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
              "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
              "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
              "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
              "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
              "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
              "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
              "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
              "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.94444,     0.94444,     0.94444, ...,           0,           0,           0],\n",
              "       [    0.95082,     0.95082,     0.95082, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
              "fitness: np.float64(1.2297046063390846)\n",
              "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)', 'metrics/precision(M)', 'metrics/recall(M)', 'metrics/mAP50(M)', 'metrics/mAP50-95(M)']\n",
              "maps: array([     1.2559,      1.2035])\n",
              "names: {0: 'goat', 1: 'sheep'}\n",
              "nt_per_class: array([54, 61])\n",
              "nt_per_image: array([13, 12])\n",
              "results_dict: {'metrics/precision(B)': 0.8817815839178069, 'metrics/recall(B)': 0.7844565877352763, 'metrics/mAP50(B)': 0.8558341127757354, 'metrics/mAP50-95(B)': 0.6665095083341048, 'metrics/precision(M)': 0.8817815839178069, 'metrics/recall(M)': 0.7844565877352763, 'metrics/mAP50(M)': 0.8607320671039331, 'metrics/mAP50-95(M)': 0.5631950980049797, 'fitness': 1.2297046063390846}\n",
              "save_dir: PosixPath('/content/runs/segment/train6')\n",
              "seg: ultralytics.utils.metrics.Metric object\n",
              "speed: {'preprocess': 0.062135523805972336, 'inference': 8.622893238095587, 'loss': 0.002477999996266417, 'postprocess': 1.357232476190499}\n",
              "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': [], 'tp_m': []}\n",
              "task: 'segment'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-IiKuP55Ww6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T_ZMHu6dYB4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "from ultralytics import YOLO,hub,checks\n",
        "ultralytics.checks()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pbRjXNPYCss",
        "outputId": "5a9f6bd2-1fa0-4288-a454-9b57c636c7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 39.4/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hub.login('a47a9d280e6b8babfc6130550b8b2924689cba4c2a')\n",
        "\n",
        "model = YOLO('https://hub.ultralytics.com/models/zgC0r7Dl06algOyUcdVT')\n",
        "results = model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SIAV_5TYG96",
        "outputId": "8f16e9dc-c695-41b6-e6d3-ca7233dc702b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['hub-sdk>=0.0.12'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.8s\n",
            "WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mNew authentication successful ✅\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mView model at https://hub.ultralytics.com/models/zgC0r7Dl06algOyUcdVT 🚀\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-seg.pt to 'yolo11n-seg.pt': 100% ━━━━━━━━━━━━ 5.9MB 129.4MB/s 0.0s\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=None, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=https://storage.googleapis.com/ultralytics-hub.appspot.com/users/JEVZ09RBpwMfvPyZt4sTHECIF5p1/datasets/wrHS9Q64nOdbrodS3kVL/V3.zip, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/segment/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://storage.googleapis.com/ultralytics-hub.appspot.com/users/JEVZ09RBpwMfvPyZt4sTHECIF5p1/datasets/wrHS9Q64nOdbrodS3kVL/V3.zip to 'V3.zip': 100% ━━━━━━━━━━━━ 76.9MB 18.6MB/s 4.1s\n",
            "\u001b[KUnzipping V3.zip to /content/datasets/GOAT...: 100% ━━━━━━━━━━━━ 1571/1571 2.4Kfiles/s 0.7s\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 29.4MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    683830  ultralytics.nn.modules.head.Segment          [2, 32, 64, [64, 128, 256]]   \n",
            "YOLO11n-seg summary: 203 layers, 2,842,998 parameters, 2,842,982 gradients, 9.7 GFLOPs\n",
            "\n",
            "Transferred 510/561 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 123.5MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1954.5±609.0 MB/s, size: 102.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/GOAT/train/labels... 738 images, 6 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 738/738 1.6Kit/s 0.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/GOAT/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.10G reserved, 0.06G allocated, 14.58G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     2842998       9.728         0.466         70.65           nan        (1, 3, 640, 640)                    list\n",
            "     2842998       19.46         1.011         31.16           nan        (2, 3, 640, 640)                    list\n",
            "     2842998       38.91         1.812         30.99           nan        (4, 3, 640, 640)                    list\n",
            "     2842998       77.82         3.372         41.56           nan        (8, 3, 640, 640)                    list\n",
            "     2842998       155.6         6.390         79.86           nan       (16, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 22 for CUDA:0 8.94G/14.74G (61%) ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2868.8±1033.9 MB/s, size: 114.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/GOAT/train/labels.cache... 738 images, 6 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 738/738 1.5Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.1 ms, read: 562.6±323.5 MB/s, size: 60.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/GOAT/valid/labels... 21 images, 1 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 21/21 676.4it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/GOAT/valid/labels.cache\n",
            "Plotting labels to /content/runs/segment/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.000515625), 100 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/segment/train\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      4.01G      1.318      2.901       2.74      1.331        109        640: 100% ━━━━━━━━━━━━ 34/34 0.8it/s 40.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.3it/s 3.0s\n",
            "                   all         21        115     0.0125      0.687      0.175     0.0759     0.0132      0.722      0.181     0.0801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/100      4.15G       1.28      2.489      1.865      1.299        101        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.847      0.152      0.372      0.212      0.781      0.128      0.263      0.107\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/100      4.15G      1.323       2.52      1.721      1.328         82        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n",
            "                   all         21        115      0.488      0.389      0.448      0.249      0.489      0.364      0.367      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/100      4.15G      1.296      2.423        1.6      1.313         89        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.428      0.523      0.454      0.241      0.382      0.468      0.351      0.108\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/100      4.16G      1.248      2.346      1.504      1.278         71        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.618      0.536      0.611      0.383      0.647      0.564      0.625      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/100      4.18G       1.22      2.279      1.427      1.265        101        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.388      0.685      0.574      0.365      0.359      0.686      0.533      0.254\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/100      4.19G      1.179      2.223      1.336      1.247         76        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         21        115      0.663      0.491      0.557      0.332      0.605      0.498      0.522      0.233\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/100      4.21G      1.165      2.197      1.267      1.234         77        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.651      0.628      0.634      0.406      0.563      0.561       0.54      0.242\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/100      4.23G      1.159      2.196       1.23      1.226         90        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2it/s 0.8s\n",
            "                   all         21        115      0.708      0.657      0.743      0.498      0.777      0.603      0.733      0.414\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/100      4.23G      1.127      2.086      1.186      1.199         69        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115      0.532      0.515      0.489      0.326      0.504      0.497      0.449      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/100      4.26G      1.111       2.08      1.166      1.208        116        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
            "                   all         21        115      0.674      0.688      0.766      0.492      0.665      0.705      0.763      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/100      4.28G       1.09      2.099      1.121      1.179         90        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.718      0.615      0.712      0.491      0.718      0.615      0.708      0.426\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/100      4.29G       1.09      2.007      1.112       1.18         86        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.728      0.691      0.777      0.534      0.727      0.695      0.779      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/100      4.31G       1.07      1.983      1.074       1.17         98        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.784      0.664      0.755      0.544      0.762       0.69      0.771      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/100      4.32G      1.045      1.983      1.039      1.164         93        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.694      0.704      0.739      0.507      0.709      0.712      0.728      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/100      4.33G      1.009      1.923     0.9829      1.139        100        640: 100% ━━━━━━━━━━━━ 34/34 1.8it/s 19.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115       0.75       0.76      0.816      0.579      0.741      0.764      0.802      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/100      4.35G       1.05      1.931       1.01      1.144        106        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.784      0.714      0.787      0.578      0.786      0.716      0.775       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/100      4.38G      1.027      1.934     0.9955       1.14        105        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 18.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115      0.795      0.787      0.817      0.603      0.781      0.772      0.796       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/100      4.38G      1.017        1.9     0.9849      1.139        100        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.774       0.74      0.773      0.547       0.79      0.739      0.794      0.468\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/100       4.4G      1.027      1.916     0.9917      1.147        105        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         21        115      0.776      0.678      0.743      0.512      0.776      0.678      0.747      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/100      4.43G      0.998      1.854     0.9623      1.134         71        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115       0.73      0.789      0.817       0.61       0.73      0.789      0.814      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/100      4.43G     0.9795      1.859     0.9424      1.126        111        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.0it/s 1.0s\n",
            "                   all         21        115      0.698       0.73      0.776      0.572      0.698       0.73      0.767      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/100      4.46G     0.9748      1.821     0.9192      1.119         82        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.5s\n",
            "                   all         21        115      0.853      0.694      0.831      0.605      0.761      0.762      0.835      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/100      4.47G     0.9671      1.771     0.8922      1.109        103        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.4it/s 0.7s\n",
            "                   all         21        115      0.757      0.729      0.759      0.566      0.736      0.747      0.752      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/100      4.47G      0.992      1.843     0.9161      1.123         93        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         21        115      0.814      0.741      0.831      0.618      0.732      0.851      0.836      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/100       4.5G     0.9849      1.815     0.8886       1.12        100        640: 100% ━━━━━━━━━━━━ 34/34 1.8it/s 18.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.701      0.718      0.724      0.532      0.708      0.726      0.726      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/100      4.52G     0.9441      1.754     0.8772      1.093        106        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 18.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.765      0.734      0.798       0.58      0.776      0.755       0.81      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/100      4.53G     0.9529      1.767     0.8805      1.107         60        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.4s\n",
            "                   all         21        115      0.737      0.788      0.789      0.593       0.73      0.783      0.778       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/100      4.55G     0.9142      1.743     0.8298       1.08        121        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.5it/s 0.4s\n",
            "                   all         21        115      0.816      0.773      0.821      0.626      0.824      0.781      0.822      0.557\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/100      4.57G     0.9108      1.756      0.842      1.078         84        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.787      0.838      0.835      0.659      0.793      0.846      0.833      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/100      4.57G     0.9175      1.739     0.8373      1.083         85        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115      0.817      0.815      0.832      0.658      0.825      0.823      0.839      0.588\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/100       4.6G      0.933      1.737     0.8466       1.09         77        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         21        115      0.781      0.795      0.813      0.639      0.779      0.807      0.818      0.562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/100      4.62G     0.8788      1.698     0.8047      1.058         85        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115       0.85      0.753      0.825      0.638       0.85      0.753      0.834      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/100      4.62G     0.8864      1.655     0.7802      1.064         93        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.0it/s 0.5s\n",
            "                   all         21        115       0.78      0.726      0.814      0.615       0.78      0.726      0.817      0.556\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/100      4.65G      0.894       1.64     0.7876      1.066         77        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1it/s 0.9s\n",
            "                   all         21        115      0.877      0.756      0.856      0.671      0.797      0.804      0.848      0.603\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/100      4.67G     0.8823      1.656     0.7882      1.072         93        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 18.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.4s\n",
            "                   all         21        115      0.836      0.805      0.854      0.677       0.84      0.799      0.854      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/100      4.68G     0.8874      1.673     0.8046      1.072         64        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115      0.846      0.784      0.852      0.663      0.846      0.784      0.853      0.599\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/100       4.7G      0.871      1.621      0.765      1.064         85        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.876      0.825      0.868      0.643      0.867      0.817      0.857      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/100      4.71G     0.8843      1.648     0.7717       1.06         93        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.793      0.745      0.819      0.636      0.793      0.745      0.813      0.564\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/100      4.72G     0.8529      1.599     0.7363      1.042        142        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 18.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.816      0.828      0.874      0.677      0.816      0.828      0.871      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/100      4.75G     0.8483      1.607     0.7408      1.051         83        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.842       0.79      0.841      0.663      0.842       0.79       0.84      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/100      4.77G     0.8668       1.61     0.7464      1.056         75        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.898      0.817      0.869      0.682      0.904      0.799      0.866      0.598\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/100      4.77G     0.8433      1.547     0.7326      1.053         97        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         21        115      0.821      0.801      0.853      0.658      0.812      0.793      0.841      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/100      4.79G     0.8351      1.562     0.7178      1.043         93        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115      0.841      0.814      0.851      0.667      0.833      0.804      0.844      0.575\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/100      4.81G      0.846      1.573     0.7292      1.044         79        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.4s\n",
            "                   all         21        115      0.828      0.799      0.859      0.703      0.828      0.799      0.853       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/100      4.82G      0.848      1.591     0.7326      1.045         96        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         21        115      0.898      0.771      0.874      0.694       0.89      0.761      0.867      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/100      4.84G     0.8495       1.58     0.7251      1.048        129        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.1it/s 0.9s\n",
            "                   all         21        115      0.863      0.794      0.859      0.644      0.853      0.786      0.848      0.608\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mUploading checkpoint https://hub.ultralytics.com/models/zgC0r7Dl06algOyUcdVT\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/100      4.87G     0.8331      1.546      0.719      1.048         74        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.7it/s 0.4s\n",
            "                   all         21        115      0.801      0.814      0.853      0.685      0.809      0.822      0.852       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/100      4.87G     0.8365      1.555     0.7124      1.033        103        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3it/s 0.8s\n",
            "                   all         21        115      0.807      0.789      0.839      0.655      0.807      0.789      0.831      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/100      4.89G     0.8278       1.54      0.714      1.033        107        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.903      0.729      0.869        0.7      0.845      0.762      0.857      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/100      4.91G     0.8206      1.537     0.6966      1.025        106        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         21        115      0.845      0.809      0.858      0.708      0.845      0.809      0.855      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/100      4.91G     0.8101      1.534     0.7007      1.033        104        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.836      0.793      0.858      0.688      0.836      0.793      0.845      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/100      4.94G     0.7854       1.47       0.68      1.015         85        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.878      0.801       0.85      0.698      0.878      0.801      0.849      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/100      4.96G     0.7995      1.508     0.6815      1.018         99        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3it/s 0.8s\n",
            "                   all         21        115      0.827      0.777      0.847      0.681      0.827      0.777      0.847      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/100      4.97G     0.7777      1.474     0.6758      1.015         80        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.866      0.794      0.867      0.693      0.866      0.794      0.849      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/100      4.99G      0.806      1.479     0.6907      1.022         96        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.4it/s 0.7s\n",
            "                   all         21        115      0.824      0.824      0.853      0.683      0.824      0.824       0.85      0.614\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/100      5.01G      0.789      1.472     0.6674      1.028         88        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.5s\n",
            "                   all         21        115      0.876      0.787       0.86      0.682      0.868      0.779       0.85      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/100      5.01G     0.7811       1.49     0.6691      1.018         72        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.872      0.831      0.846      0.668      0.872      0.831      0.843      0.611\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/100      5.04G     0.7793      1.439     0.6506      1.009         71        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.5s\n",
            "                   all         21        115      0.885      0.774      0.863      0.679      0.885      0.774      0.861      0.627\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/100      5.06G     0.7796       1.44     0.6516      1.012         78        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         21        115      0.817      0.843      0.875      0.698      0.809      0.835      0.857      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/100      5.06G     0.7764      1.484     0.6694      1.019        127        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.0it/s 1.0s\n",
            "                   all         21        115       0.82      0.809      0.851       0.69       0.82      0.809      0.847      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/100      5.09G     0.7821      1.464     0.6541      1.017         71        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.889      0.767      0.855      0.701      0.879      0.758      0.843      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/100      5.11G     0.7482      1.402     0.6203     0.9996         84        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         21        115      0.846      0.787      0.845      0.683      0.846      0.787      0.833      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/100      5.11G      0.761      1.429     0.6453      1.001         85        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.822      0.777      0.847      0.694      0.805      0.801      0.837      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/100      5.14G     0.7494      1.412     0.6169      0.996        122        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.4it/s 0.7s\n",
            "                   all         21        115      0.827      0.798      0.842      0.688      0.826      0.801      0.835      0.597\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/100      5.16G     0.7467      1.393     0.6109     0.9933         95        640: 100% ━━━━━━━━━━━━ 34/34 1.8it/s 18.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115      0.854      0.815      0.845      0.692      0.854      0.815      0.832      0.615\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/100      5.16G     0.7438       1.42     0.6267     0.9903        122        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
            "                   all         21        115      0.813      0.797      0.849      0.683      0.821        0.8      0.856      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/100      5.19G     0.7352      1.384     0.6153     0.9881         89        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 18.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.6s\n",
            "                   all         21        115      0.842        0.8      0.848      0.687      0.833      0.792      0.842      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/100      5.21G     0.7526      1.423     0.6128     0.9911         75        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.5it/s 0.7s\n",
            "                   all         21        115      0.841        0.8      0.844      0.692      0.832      0.792      0.831      0.616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/100      5.21G       0.75      1.374     0.6254      1.003         80        640: 100% ━━━━━━━━━━━━ 34/34 1.8it/s 18.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.862      0.792      0.861      0.707      0.862      0.792      0.852      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/100      5.23G     0.7377      1.383     0.6118          1        100        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         21        115      0.894      0.782      0.858      0.692      0.895      0.779      0.852      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/100      5.25G     0.7325      1.393     0.5981     0.9843        101        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 18.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3it/s 0.8s\n",
            "                   all         21        115      0.882      0.811      0.866      0.716      0.882      0.811      0.852      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/100      5.26G     0.7246      1.392     0.6001     0.9897        100        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         21        115      0.833      0.793      0.845      0.705      0.833      0.793      0.836       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/100      5.29G     0.7133       1.34     0.5807     0.9819         93        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2it/s 0.8s\n",
            "                   all         21        115       0.82      0.835      0.858      0.711      0.812      0.827      0.848      0.637\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/100       5.3G      0.716      1.351      0.579     0.9806         89        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.853      0.802      0.851      0.705      0.843      0.794       0.84      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/100       5.3G     0.7113      1.347     0.5839       0.98         92        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.834      0.783      0.842      0.685      0.834      0.783      0.829      0.617\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/100      5.33G     0.7262      1.365     0.5932     0.9852        100        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         21        115      0.867      0.773      0.847      0.694      0.867      0.773      0.835      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/100      5.35G     0.7077      1.323     0.5687     0.9792        141        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115      0.861      0.775      0.847      0.705      0.861      0.775      0.841      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/100      5.36G     0.7063      1.312     0.5737     0.9846         97        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.886      0.784      0.855       0.71      0.886      0.784      0.846      0.639\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/100      5.38G     0.7142      1.343     0.5815       0.98         86        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         21        115      0.845      0.806      0.849      0.699      0.854      0.813      0.849      0.646\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/100       5.4G     0.7022      1.307     0.5572     0.9668        119        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.1it/s 0.5s\n",
            "                   all         21        115      0.877      0.785      0.867      0.725      0.877      0.785      0.861      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/100       5.4G     0.6926      1.318     0.5686      0.971         76        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.9it/s 0.5s\n",
            "                   all         21        115      0.835      0.781      0.864      0.732      0.844      0.789      0.854      0.643\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/100      5.43G     0.6905      1.313     0.5664     0.9732        100        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 16.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.3it/s 0.8s\n",
            "                   all         21        115      0.855      0.809      0.866      0.728      0.855      0.809      0.859       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/100      5.45G     0.7002      1.315     0.5649     0.9812         72        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115      0.847      0.793       0.85      0.715       0.82      0.768      0.809      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/100      5.46G     0.6797      1.286     0.5522     0.9636         90        640: 100% ━━━━━━━━━━━━ 34/34 1.8it/s 18.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.2it/s 0.8s\n",
            "                   all         21        115      0.856      0.751       0.84      0.698      0.856      0.751      0.832      0.622\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/100      5.48G     0.6867      1.269     0.5523     0.9624        103        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.8it/s 0.6s\n",
            "                   all         21        115      0.892      0.792      0.848      0.705      0.892      0.792      0.843      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/100       5.5G     0.6696      1.283       0.55     0.9668         86        640: 100% ━━━━━━━━━━━━ 34/34 2.0it/s 17.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.869      0.801      0.854      0.708      0.851      0.788      0.813      0.612\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/100       5.5G     0.6694      1.264     0.5373     0.9617        119        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 18.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.836      0.827      0.858      0.722      0.836      0.827      0.849      0.645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/100      5.53G     0.6746      1.278     0.5389     0.9594         86        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115       0.85      0.788      0.853      0.713       0.85      0.788      0.844      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/100      5.54G     0.6764      1.248     0.5434     0.9599        113        640: 100% ━━━━━━━━━━━━ 34/34 1.9it/s 17.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.6it/s 0.6s\n",
            "                   all         21        115       0.84      0.797      0.847      0.704       0.84      0.797      0.841      0.643\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/100      5.55G     0.6409      1.219     0.5242     0.9479         53        640: 100% ━━━━━━━━━━━━ 34/34 1.8it/s 18.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.4it/s 0.4s\n",
            "                   all         21        115      0.846      0.792      0.845      0.704      0.846      0.792      0.843      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/100      5.58G     0.6247      1.182     0.4828     0.9371         47        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 16.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         21        115       0.84      0.798      0.845      0.701       0.86      0.802      0.845      0.629\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/100       5.6G     0.6125      1.171     0.4746     0.9328         51        640: 100% ━━━━━━━━━━━━ 34/34 2.3it/s 14.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.2it/s 0.5s\n",
            "                   all         21        115      0.868      0.784      0.852      0.706      0.877      0.793      0.855      0.624\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/100       5.6G      0.615      1.164     0.4708     0.9282         57        640: 100% ━━━━━━━━━━━━ 34/34 2.3it/s 15.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         21        115      0.897      0.774      0.858      0.696      0.897      0.774      0.854       0.63\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/100      5.63G     0.6063       1.14     0.4644     0.9324         40        640: 100% ━━━━━━━━━━━━ 34/34 2.2it/s 15.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.6it/s 0.4s\n",
            "                   all         21        115      0.894      0.782      0.857      0.708      0.894      0.782      0.852      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/100      5.64G     0.5941      1.129     0.4537     0.9291         67        640: 100% ━━━━━━━━━━━━ 34/34 2.1it/s 15.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.833      0.832      0.861      0.711      0.879      0.787      0.853       0.64\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mUploading checkpoint https://hub.ultralytics.com/models/zgC0r7Dl06algOyUcdVT\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/100      5.65G     0.5949      1.118     0.4513      0.924         54        640: 100% ━━━━━━━━━━━━ 34/34 2.2it/s 15.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.1it/s 0.3s\n",
            "                   all         21        115      0.874      0.778      0.858       0.71      0.874      0.778      0.845      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/100      5.68G     0.5927       1.12     0.4543     0.9149         63        640: 100% ━━━━━━━━━━━━ 34/34 2.3it/s 14.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.3it/s 0.4s\n",
            "                   all         21        115      0.886      0.793      0.857       0.71      0.886      0.793      0.847      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/100       5.7G     0.5805      1.124      0.444     0.9194         48        640: 100% ━━━━━━━━━━━━ 34/34 2.2it/s 15.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         21        115      0.883      0.793      0.861      0.714      0.883      0.793      0.847      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/100       5.7G     0.5817      1.116     0.4442     0.9204         49        640: 100% ━━━━━━━━━━━━ 34/34 2.3it/s 15.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 1.7it/s 0.6s\n",
            "                   all         21        115      0.884      0.784       0.86      0.709      0.884      0.784      0.848       0.64\n",
            "\n",
            "100 epochs completed in 0.525 hours.\n",
            "Optimizer stripped from /content/runs/segment/train/weights/last.pt, 6.0MB\n",
            "Optimizer stripped from /content/runs/segment/train/weights/best.pt, 6.0MB\n",
            "\n",
            "Validating /content/runs/segment/train/weights/best.pt...\n",
            "Ultralytics 8.3.204 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-seg summary (fused): 113 layers, 2,834,958 parameters, 0 gradients, 9.6 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.0it/s 0.3s\n",
            "                   all         21        115      0.835      0.781      0.864      0.731      0.844      0.789      0.854      0.643\n",
            "                  goat         13         54      0.862      0.807      0.872       0.78      0.862      0.807      0.851      0.647\n",
            "                 sheep         12         61      0.808      0.754      0.856      0.682      0.826       0.77      0.857       0.64\n",
            "Speed: 0.2ms preprocess, 2.8ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/segment/train\u001b[0m\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mSyncing final model...\n",
            "\u001b[K: 100% ━━━━━━━━━━━━ 5.7MB 4.3MB/s 1.3s\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mDone ✅\n",
            "\u001b[34m\u001b[1mUltralytics HUB: \u001b[0mView model at https://hub.ultralytics.com/models/zgC0r7Dl06algOyUcdVT 🚀\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjXf00usYe0b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}